{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\t\t\n",
    "<p></p>\n",
    "<p></p>\n",
    "<font size=5>\n",
    "In the Name of God\n",
    "<font/>\n",
    "<p></p>\n",
    " <br/>\n",
    "    <br/>\n",
    "    <br/>\n",
    "<font color=#FF7500>\n",
    "Sharif University of Technology - Departmenet of Computer Engineering\n",
    "</font>\n",
    "<p></p>\n",
    "<font color=blue>\n",
    "Artifical Intelligence - Dr. Mohammad Hossein Rohban\n",
    "</font>\n",
    "<br/>\n",
    "<br/>\n",
    "Fall 2021\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr/>\n",
    "\t\t<div align=center>\n",
    "\t\t    <font color=red size=6>\n",
    "\t\t\t    <br />\n",
    "Practical Assignment 3\n",
    "            \t<br/>\n",
    "\t\t\t</font>\n",
    "    <br/>\n",
    "    <br/>\n",
    "<font size=4>\n",
    "\t\t\t<br/><br/>\n",
    "Deadline: Azar 18th\n",
    "                <br/><b>\n",
    "              Cheating is Strongly Prohibited\n",
    "                </b><br/><br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true,
    "execution": {
     "iopub.execute_input": "2021-10-01T16:01:36.762477Z",
     "iopub.status.busy": "2021-10-01T16:01:36.762155Z",
     "iopub.status.idle": "2021-10-01T16:01:36.764025Z",
     "shell.execute_reply": "2021-10-01T16:01:36.763754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set your student number\n",
    "student_number = 98000000\n",
    "Name = ''\n",
    "Last_Name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules\n",
    "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**. \n",
    "- There is one cell for your custom functions (if you need any) at the beginning of each question. Please note that this jupyter file might be broken down into 3 or 4 jupyter notebooks for easier grading, so you **must write your custom functions in the correct cell**.\n",
    "- By running the cell below, you can see if your jupyter file is accepted or not. This cell will also **generate a python file which you'll have to upload to Quera** (as well as your jupyter file). The python file will later be validated and if the code in both files doesn't match, **your Practical Assignment won't be graded**.\n",
    "- This assignment is due Azar 18th 23:59:59. you can use up to 10 grace days for this assignment and the hard deadline is Azar 28th 23:59:59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to save your jupyter file before running this script\n",
    "from Helper_codes.validator import *\n",
    "\n",
    "python_code = extract_python(\"./questions.ipynb\")\n",
    "with open(f'python_code_{student_number}.py', 'w') as file:\n",
    "    file.write(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 (30+5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Author: Pooya Moini\n",
    "\t\t\t<br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collectable": true
   },
   "source": [
    "# Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment, we will investigate the structure of the binarized MNIST dataset of handwritten digits using Bayesian networks. The dataset contains images of handwritten digits with dimensions $28 \\times 28$ (784) pixels. Consider the Bayesian network in Figure 1 . The network contains two layers of variables. The variables in the bottom layer, $X_{1: 784}$ denote the pixel values of the flattened image. The variables in the top layer, $Z_{1}$ and $Z_{2}$, are referred to as latent variables, because the value of these variables will not be explicitly provided by the data and will have to be inferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure1](./Images/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian network specifies a joint probability distribution over binary images and latent variables $p\\left(Z_{1}, Z_{2}, X_{1: 784}\\right)$. The model is trained so that the marginal probability of the manifest variables, $p\\left(x_{1: 784}\\right)=\\sum_{z_{1}, z_{2}} p\\left(z_{1}, z_{2}, x_{1: 784}\\right)$ is high on images that look like digits, and low for other images. \n",
    "\n",
    "For this programming assignment, we provide a pretrained model trained_mnist_model. The starter code loads this model and provides functions to directly access the conditional probability tables. Further, we simplify the problem by discretizing the latent and manifest variables such that $\\operatorname{Val}\\left(Z_{1}\\right)=\\operatorname{Val}\\left(Z_{2}\\right)=\\{-3,-2.75, \\ldots, 2.75,3\\}$ and $\\operatorname{Val}\\left(X_{j}\\right)=\\{0,1\\}$, i.e., the image is binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "How many values can the random vector $X_{1: 784}$ take, i.e., how many different $28 \\times 28$ binary images are there?\n",
    "\n",
    "How many parameters would you need to specify an arbitrary probability distribution over all possible $28 \\times 28$ binary images? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# Write here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below codes to load the network and its functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "NUM_PIXELS = 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_z1(z1_val):\n",
    "    '''\n",
    "    Helper. Computes the prior probability for variable z1 to take value z1_val.\n",
    "    P(Z1=z1_val)\n",
    "    '''\n",
    "\n",
    "    return bayes_net['prior_z1'][z1_val]\n",
    "\n",
    "\n",
    "def get_p_z2(z2_val):\n",
    "    '''\n",
    "    Helper. Computes the prior probability for variable z2 to take value z2_val.\n",
    "    P(Z2=z2_val)\n",
    "    '''\n",
    "\n",
    "    return bayes_net['prior_z2'][z2_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_xk_cond_z1_z2(z1_val, z2_val, k):\n",
    "    '''\n",
    "    Helper. Computes the conditional probability that variable xk assumes value 1\n",
    "    given that z1 assumes value z1_val and z2 assumes value z2_val\n",
    "    P(Xk = 1 | Z1=z1_val , Z2=z2_val)\n",
    "    '''\n",
    "\n",
    "    return bayes_net['cond_likelihood'][(z1_val, z2_val)][0, k-1]\n",
    "\n",
    "\n",
    "def get_p_x_cond_z1_z2(z1_val, z2_val):\n",
    "    '''\n",
    "    Computes the conditional probability of the entire vector x for x = 1,\n",
    "    given that z1 assumes value z1_val and z2 assumes value z2_val\n",
    "    '''\n",
    "    pk = np.zeros(NUM_PIXELS)\n",
    "    for i in range(NUM_PIXELS):\n",
    "        pk[i] = get_p_xk_cond_z1_z2(z1_val, z2_val, i+1)\n",
    "    return pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    '''\n",
    "    Loads a default Bayesian network with latent variables (in this case, a\n",
    "    variational autoencoder)\n",
    "    '''\n",
    "\n",
    "    with open('Helper_codes/trained_mnist_model', 'rb') as infile:\n",
    "        cpts = pkl.load(infile, encoding='bytes')\n",
    "\n",
    "    model = {}\n",
    "    model['prior_z1'] = cpts[0]\n",
    "    model['prior_z2'] = cpts[1]\n",
    "    model['cond_likelihood'] = cpts[2]\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global disc_z1, disc_z2\n",
    "n_disc_z = 25\n",
    "disc_z1 = np.linspace(-3, 3, n_disc_z)\n",
    "disc_z2 = np.linspace(-3, 3, n_disc_z)\n",
    "\n",
    "global bayes_net\n",
    "bayes_net = load_model('Helper_codes/trained_mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "Produce 5 samples from the joint probability distribution $\\left(z_{1}, z_{2}, x_{1: 784}\\right) \\sim p\\left(Z_{1}, Z_{2}, X_{1: 784}\\right)$, and plot the corresponding images (values of the pixel variables). (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# write here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "For each possible value of\n",
    "$$\n",
    "\\left(\\bar{z}_{1}, \\bar{z}_{2}\\right) \\in\\{-3,-2.75, \\ldots, 2.75,3\\} \\times\\{-3,-2.75, \\ldots, 2.75,3\\}\n",
    "$$\n",
    "compute the conditional expectation $E\\left[X_{1: 784} \\mid Z_{1}, Z_{2}=\\left(\\bar{z}_{1}, \\bar{z}_{2}\\right)\\right] .$ This is the expected image corresponding to each possible value of the latent variables $Z_{1}, Z_{2} .$ Plot the images on on a $2 \\mathrm{D}$ grid where the grid axes correspond to $Z_{1}$ and $Z_{2}$ respectively. What is the intuitive role of the $Z_{1}, Z_{2}$ variables in this model? (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# write here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('Helper_codes/testval.mat')\n",
    "val_data = mat['val_x']\n",
    "test_data = mat['test_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "You are given a validation and a test dataset. In the test dataset, some images are \"real\" handwritten digits, and some are anomalous (corrupted images). We would like to use our Bayesian network to distinguish real images from the anomalous ones. Intuitively, our Bayesian network should assign low probability to corrupted images and high probability to the real ones, and we can use this for classification. To do this, we first compute the average marginal log-likelihood,\n",
    "$$\n",
    "\\log p\\left(x_{1: 784}\\right)=\\log \\sum_{z_{1}} \\sum_{z_{2}} p\\left(z_{1}, z_{2}, x_{1: 784}\\right)\n",
    "$$\n",
    "on the validation dataset, and the standard deviation (again, standard deviation over the validation set). Consider a simple prediction rule where images with marginal log-likelihood, $\\log p\\left(x_{1: 784}\\right)$, outside three standard deviations of the average marginal log-likelihood are classified as corrupted. Classify images in the test set as corrupted or real using this rule. Then plot a histogram of the marginal log-likelihood for the images classified as \"real\". Plot a separate histogram of the marginal log-likelihood for the images classified as \"corrupted\". (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# write here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 (40 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Author: Mohammad Mahdi Asmae\n",
    "\t\t\t<br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collectable": true
   },
   "source": [
    "# Sampling in Bayesian Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will implement diffrent methods of sampling and try to compare the methods by varying queries and number of samples. In the next section you will implement Bayesian Network as a Python class with these methods:\n",
    "\n",
    "* CPT: returns conditional probability table of nodes\n",
    "* PMF: returns probability mass function of given query\n",
    "* Sampling: implementation of different sampling methods\n",
    "    \n",
    "We will use following BN in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/BN.png\" width=1400 height=1200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# import necessary packages in this cell                   #\n",
    "# please set a random seed to get the same results in      #\n",
    "# different runs (1 Points)                                #\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "class BN(object):\n",
    "    \"\"\"\n",
    "    Bayesian Network implementation with sampling methods as a class\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    n: int\n",
    "        number of variables\n",
    "        \n",
    "    G: dict\n",
    "        Network representation as a dictionary. \n",
    "        {variable:[[children],[parents]]} # You can represent the network in other ways. This is only a suggestion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        ############################################################\n",
    "        # Initialzie Bayesian Network                              #\n",
    "        # (1 Points)                                               #\n",
    "        ############################################################\n",
    "        \n",
    "        #Your code\n",
    "        pass\n",
    "    \n",
    "    def cpt(self, node, value) -> dict:\n",
    "        \"\"\"\n",
    "        This is a function that returns cpt of the given node\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node:\n",
    "            a variable in the bayes' net\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        result: dict\n",
    "            {value1:{{parent1:p1_value1, parent2:p2_value1, ...}: prob1, ...}, value2: ...}\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        # (3 Points)                                               #\n",
    "        ############################################################\n",
    "        \n",
    "        #Your code\n",
    "        pass\n",
    "    \n",
    "    def pmf(self, query, evidence) -> float:\n",
    "        \"\"\"\n",
    "        This function gets a variable and its value as query and a list of evidences and returns probability mass function P(Q=q|E=e)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query:\n",
    "            a variable and its value\n",
    "            e.g. ('a', 1)\n",
    "        evidence:\n",
    "            list of variables and their values\n",
    "            e.g. [('b', 0), ('c', 1)]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        PMF: float\n",
    "            P(query|evidence)\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        # (3 Points)                                               #\n",
    "        ############################################################\n",
    "        \n",
    "        #Your code\n",
    "        pass\n",
    "    \n",
    "    def sampling(self, query, evidence, sampling_method, num_iter, num_burnin = 1e2) -> float:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: list\n",
    "            list of variables an their values\n",
    "            e.g. [('a', 0), ('e', 1)]\n",
    "        evidence: list\n",
    "            list of observed variables and their values\n",
    "            e.g. [('b', 0), ('c', 1)]\n",
    "        sampling_method:\n",
    "            \"Prior\", \"Rejection\", \"Likelihood Weighting\", \"Gibbs\"\n",
    "        num_iter:\n",
    "            number of the generated samples \n",
    "        num_burnin:\n",
    "            (used only in gibbs sampling) number of samples that we ignore at the start for gibbs method to converge\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        probability: float\n",
    "            approximate P(query|evidence) calculated by sampling\n",
    "        \"\"\"\n",
    "        ############################################################\n",
    "        # (27 Points)                                              #\n",
    "        #     Prior sampling (6 points)                            #\n",
    "        #     Rejection sampling (6 points)                        #\n",
    "        #     Likelihood weighting (7 points)                      #\n",
    "        #     Gibbs sampling (8 points)                      #\n",
    "        ############################################################\n",
    "        \n",
    "        #Your code\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will compare sampling results with real probabilities for these settings:\n",
    "\n",
    "* query: $P(F=1|A=1,E=0)$ , $P(C=0,B=1|F=1,D=0)$\n",
    "* number of samples: 100, 500, 1000, 3000, 10000, 50000\n",
    "\n",
    "First find the probabilities with inference methods, then find the approximate probabilities for the queries with sampling methods with different number of samples. At the end, you will plot errors of diffrent methods by number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# x-axis: number of samples                                #\n",
    "# y-axis: error                                            #\n",
    "# Your plot have to contain errors for all diffrent        #\n",
    "# methods of sampling that you've implemented (3 Points)   #\n",
    "############################################################\n",
    "\n",
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gibbs sampling, try diffrent burnin values and report the accuracy (or error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# (2 Points)                                         #\n",
    "############################################################\n",
    "\n",
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 (20+ 5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Author: Kian Bakhtari\n",
    "\t\t\t<br/>\n",
    "                <font color=red>\n",
    "Please run all the cells.\n",
    "     </font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Puerto Princesa ship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At midnight on a fall day in the Philippines, a ship leaves Puerto Princesa City's seaport to Macao, China. After one or two hours, the boat loses its GPS connection because of a technical issue. Captain keeps navigating the ship to its destination, using the stars and four old radio towers, which you can see on the map. Each antenna could measure the ship's coordinates (X, Y) and send them to its receiver. There are five records of towers signals at five different times, available for you in the records.json file. Also, the boat's actual coordinates are available in the real_coordinates.json file. The exact coordinates are ONLY FOR EVALUATION PURPOSES, and you CAN NOT use them as input data. The five dots on the map below are actual coordinates of the ship, at each time step where the records from antennas were received. Also, the map is decorative and is not part of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure3-1](./Images/map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tower has a noise that is coming from a gaussian distribution, meaning that every (X, Y) pair that is received from an antenna is actually derived from:\n",
    "\n",
    "X = sample_from_normal_distribution(mean = X_real, std = antenna's std)\n",
    "Y = sample_from_normal_distribution(mean = Y_real, std = antenna's std)\n",
    "\n",
    "Information of radio towers (coordinate and noise standard deviation) is available in the towers_info.json file.\n",
    "\n",
    "The ship's movement between those five different time steps could be mathematically modeled as follows:\n",
    "At each time step, the ship moves D units to the north and F units to either east or west (half of the times west, and half of the times east). D and F are both samples from exponential distributions with a scale of Y_STEP and X_STEP, respectively. Those parameters are available in the moving_model.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can build a simple HMM and estimate the ship's coordinates using the conditional probabilities that you have. For each time step, calculate the ship's coordinates at that time step and previous time steps, using the tower records received up to that time. In simpler words, calculate:<br>\n",
    "\n",
    "P(coor_0 | records_0)<br>\n",
    "P(coor_1 | records_0, records_1)<br>\n",
    "...<br>\n",
    "P(coor_4 | records_0, records_1, records_2, records_3, records_4)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual coordinates of the ship in the first time step (coor_0) is coming from a 2-dimensional guassian distribution with the mean of Puerto Princesa city's coordinates and covarianve matrix of INIT_COV (scalar) times the identity matrix. INIT_COV and coordinates of Puerto Princesa city is availabel in moving_model.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "from scipy.stats import norm, expon\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_coordinates = json.load(open('./inputs/real_coordinates.json'))\n",
    "pd.DataFrame(real_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towers_info = json.load(open('./inputs/towers_info.json'))\n",
    "pd.DataFrame(towers_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_model = json.load(open('./inputs/moving_model.json'))\n",
    "moving_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = json.load(open('./inputs/records.json'))\n",
    "pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_records = [(records.get('Tower1')[i],\n",
    "                  records.get('Tower2')[i], \n",
    "                  records.get('Tower3')[i], \n",
    "                  records.get('Tower4')[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "def get_mean_towers_coor(time_step: int, tower_records: list):\n",
    "    # The average of all four towers measurements at a given time step\n",
    "    x = np.average([tower_coor[0] for tower_coor in tower_records[time_step]])\n",
    "    y = np.average([tower_coor[1] for tower_coor in tower_records[time_step]])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def P_coor0(coor0):\n",
    "    # Distribuiton of initial coordinates (time step 0)\n",
    "    x0, y0 = coor0\n",
    "    return scipy.stats.multivariate_normal.pdf([x0, y0], \n",
    "                            mean=moving_model.get('Peurto_coordinates'), cov=moving_model.get('INIT_COV'))\n",
    "\n",
    "\n",
    "# filling these three functions with apropriate codes: (2 points)\n",
    "\n",
    "def P_coor_given_prevCoor(coor, prev_coor):\n",
    "    # Probability of coordinates at time step i, given the coordinates of time step i-1\n",
    "    ############################################################\n",
    "    #                                                          #\n",
    "    #                    Your code here                        #\n",
    "    #                                                          #\n",
    "    #                                                          #\n",
    "    ############################################################\n",
    "    pass\n",
    "\n",
    "    \n",
    "def P_towerCoor_given_coor(tower_coor, tower_std, coor):\n",
    "    # Probability of a tower measurement, given the coordinates of the ship\n",
    "    ############################################################\n",
    "    #                                                          #\n",
    "    #                    Your code here                        #\n",
    "    #                                                          #\n",
    "    #                                                          #\n",
    "    ############################################################\n",
    "    pass\n",
    "    \n",
    "    \n",
    "def P_record_given_coor(rec, coor, towers_info):\n",
    "    # All four measurements of all four towers at time step i, is called the record of thime step i.\n",
    "    # This function returns the probability of a record given the ship's coordinates.\n",
    "    ############################################################\n",
    "    #                                                          #\n",
    "    #                    Your code here                        #\n",
    "    #                                                          #\n",
    "    #                                                          #\n",
    "    ############################################################\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_coor(time_step):\n",
    "    return round(real_coordinates.get('X')[time_step]), round(real_coordinates.get('Y')[time_step])\n",
    "\n",
    "def dist(coor_a, coor_b):\n",
    "    return round(np.sqrt((coor_a[0] - coor_b[0])**2 + (coor_a[1] - coor_b[1])**2))\n",
    "\n",
    "coor0_estimations = []\n",
    "coor1_estimations = []\n",
    "coor2_estimations = []\n",
    "coor3_estimations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating coordinates_0 from P(coor_0) and record_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, you can see the approach for finding the argmax of P(coor_0 | record_0), which is equal to argmax of P(record_0 | coor_0) times P(coor_0).\n",
    "We are not using derivatives to find the argmax, we are actually doing it numerically by trying different coordinates and seeing which one provides the highest probability. <br>\n",
    "\n",
    "#### Recommended approach: You can use gradient descent to find the argmax of probability function, and that will give you 5 extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax P(coor_0 | record_0) = argmax P(record_0 | coor_0) P(coor_0)\n",
    "\n",
    "best_x0, best_y0 = None, None\n",
    "\n",
    "max_Px, max_Py = 0, 0\n",
    "interval, step = 30, 5\n",
    "# Larger interval and smaller step will lead to a more accurate result, but will increase computational \n",
    "# complexity deramaticly. Feel free to use other approaches like running this cell more than once and tighten\n",
    "# the searching interval with smaller steps. \n",
    "# Recommended approach: You can use gradient descent to find the argmax of probability\n",
    "# function, and that will give you 5 extra points.\n",
    "\n",
    "towers_mean_x0, towers_mean_y0 = get_mean_towers_coor(0, tower_records)\n",
    "\n",
    "for x0 in range(int(towers_mean_x0 - interval), int(towers_mean_x0 + interval), step):\n",
    "    for y0 in range(int(towers_mean_y0 - interval), int(towers_mean_y0 + interval), step):\n",
    "        \n",
    "        coor0 = (x0, y0)\n",
    "        rec0 = tower_records[0]\n",
    "\n",
    "        P_rec0_given_x0, P_rec0_given_y0 = P_record_given_coor(rec0, coor0, towers_info)\n",
    "        p_c0 = P_coor0(coor0)\n",
    "    \n",
    "        Px = P_rec0_given_x0 * p_c0\n",
    "        Py = P_rec0_given_y0 * p_c0\n",
    "\n",
    "        if Px > max_Px:\n",
    "            best_x0 = x0\n",
    "            max_Px = Px\n",
    "\n",
    "        if Py > max_Py:\n",
    "            best_y0 = y0\n",
    "            max_Py = Py\n",
    "\n",
    "\n",
    "coor0_estimations.append((best_x0, best_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'real_coor0: {real_coor(0)} - Estimated_coor0: {best_x0, best_y0}')\n",
    "print(f'Estimation_error: {dist((best_x0, best_y0), real_coor(0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating coordinates_0 and coordinates_1 from P(coor_0), record_0, and record_1<br>(4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# argmax P(coor_0 | record_0, record_1)\n",
    "# argmax P(coor_1 | coor_0, record_0, record_1)\n",
    "\n",
    "\n",
    "max_Px, max_Py = 0, 0\n",
    "interval, step = 20, 5\n",
    "\n",
    "best_x0, best_y0 = None, None\n",
    "best_x1, best_y1 = None, None\n",
    "\n",
    "towers_mean_x1, towers_mean_y1 = get_mean_towers_coor(1, tower_records)\n",
    "\n",
    "for x0 in range(int(coor0_estimations[-1][0] - interval), int(coor0_estimations[-1][0] + interval), step):\n",
    "    for y0 in range(int(coor0_estimations[-1][1] - interval), int(coor0_estimations[-1][1] + interval), step):\n",
    "        \n",
    "         for x1 in range(int(towers_mean_x1 - interval), int(towers_mean_x1 + interval), step):\n",
    "            for y1 in range(int(towers_mean_y1 - interval), int(towers_mean_y1 + interval), step):\n",
    "                    \n",
    "                coor0 = (x0, y0)\n",
    "                coor1 = (x1, y1)\n",
    "\n",
    "                rec0 = tower_records[0]\n",
    "                rec1 = tower_records[1]\n",
    "\n",
    "        # Similiar to the cell above, calculate the best estimation\n",
    "        # of coordinates_0 and coordinates_1\n",
    "        ############################################################\n",
    "        #                                                          #\n",
    "        #                    Your code here                        #\n",
    "        #                                                          #\n",
    "        #                                                          #\n",
    "        ############################################################\n",
    "                    \n",
    "            \n",
    "coor0_estimations.append((best_x0, best_y0))\n",
    "coor1_estimations.append((best_x1, best_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'real_coor0: {real_coor(0)} - Estimated_coor0: {best_x0, best_y0}')\n",
    "print(f'Estimation_error: {dist((best_x0, best_y0), real_coor(0))}')\n",
    "print()\n",
    "print(f'real_coor1: {real_coor(1)} - Estimated_coor1: {best_x1, best_y1}')\n",
    "print(f'Estimation_error: {dist((best_x1, best_y1), real_coor(1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating coordinates_0, coordinates_1 and coordinates_2 from P(coor_0), record_0, record_1, and record_2 <br> (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                                                          #\n",
    "#                    Your code here                        #\n",
    "#                                                          #\n",
    "#                                                          #\n",
    "############################################################\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating coordinates_0, coordinates_1, coordinates_2, and coordinates_3 from  P(coor_0), record_0, record_1, record_2, and record_3 <br> (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                                                          #\n",
    "#                    Your code here                        #\n",
    "#                                                          #\n",
    "#                                                          #\n",
    "############################################################\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know from the theoretical aspect, and you can see from your results, the errors of estimations decrease when you use more records and conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot curves that show using more records, leads to decrease of estimation error.<br>( 6 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                                                          #\n",
    "#                    Your code here                        #\n",
    "#                                                          #\n",
    "#                                                          #\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collectable": true
   },
   "outputs": [],
   "source": [
    "# extra space"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f336af7d54ba0f0c1daaf2256eb85f31e983e88153daf7a27ef3ea6c724faba4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
